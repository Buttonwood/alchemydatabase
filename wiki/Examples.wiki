#labels Featured
= Alchemy Database Examples =

*[http://code.google.com/p/alchemydatabase/wiki/Examples#MYSQL_EXAMPLES Jump to examples for Mysql users]*<br/>
*[http://code.google.com/p/alchemydatabase/wiki/Examples#REDIS_EXAMPLES Jump to examples for Redis users]*<br/>
*[http://code.google.com/p/alchemydatabase/wiki/Examples#INSWAP_EXAMPLE Jump to examples for InSwapMode example]*<br/>
<br/>

Alchemy Database provides a single home for your SQL and NOSQL data. Its event driven fast and you can effectively use all of your RAM (even go into swap if you arent scared) to store your data and have it retrieved consistently at RAM speed<br/>

The following examples showcase how Alchemy Database can
  * transform SQL data to NOSQL data structures (denormalise and go schemaless)
  * transfrom NOSQL data into SQL tables (normalise to save RAM or to backup to a RDBMS)
  * transfrom various NOSQL data structures to other NOSQL data structures (repackage your data to your use case)

<br/>
== MYSQL EXAMPLES ==
=== MYSQL EXAMPLE ONE: SQL tables at NOSQL speed ===
If your database is bottlenecking and you need NOSQL speed, that is what Alchemy Database was built for<br/>
Alchemy Database is a full relational database and is VERY fast
  # export table(s) to Alchemy Database (e.g. w/ Ruby function [https://github.com/JakSprats/redis-rb/blob/master/examples/schemaless.rb#L16-61 import_from_mysql]), 
  # cutover your application to use an Alchemy Database library (which speak SQL and support RDBMS functionality, meaning you simply switch libraries and maybe rename a few functions, if your current mysql library uses non standard function names)
  # That's it, you are set 
  # The Alchemy Database server can even be on a different machine if you want to free up resources for your mysql-server
Best to [http://code.google.com/p/alchemydatabase/wiki/CommandReference read] up on the SQL that Alchemy Database supports and what it does not support, if you are following best OLTP practices, you should be good to go.<br/>
Also note that joining a Mysql table w/ a Alchemy Database during runtime is not yet supported
<br/><br/>

=== MYSQL EXAMPLE TWO: Try NOSQL out ===
Curious about NOSQL? Want to try it out w/o the risk of data lock in, use Alchemy Database. Alchemy Database provides mechanisms to get your data into any Alchemy Database/redis data-structure and get it back out, there is no risk of product data lock in. To go schemaless:<br/>
  # export your mysql table into Alchemy Database (w/ simple [https://github.com/JakSprats/redis-rb/blob/master/examples/schemaless.rb scripts]), 
  # denormalise Alchemy Database's tables into ANY redis datastructure (LIST,SET,ZSET,HASH) using the SELECT STORE syntax, which provides the possibilities to break up tables any way you want
{{{
SELECT ....
FROM table
WHERE ....
STORE redis_command redis_object
}}}
   * Hash Table "user_pass" - lookup passwords directly using "name" (and the hash table is only as big as the results of the WHERE Clause)
{{{
SELECT name, passwd FROM user WHERE ... STORE HSET user_pass
}}}
   * ZSET "user_action" - you can now perform set logic on user actions OR range query via timestamp
{{{
SELECT timestamp, action FROM user_history WHERE ... STORE ZSET user_action
}}}
   * mysql-to-Alchemy Database-export and table-denormalisation are demo'ed [https://github.com/JakSprats/redis-rb/blob/master/examples/schemaless.rb here]
  # Go hog wild w/ your new NOSQL Data. You are schemaless, you have lists, queues, sets, ordered sets, hash tables, message queues ....
  # if you find NOSQL wasnt the right fit for your problem, then export your redis datastructures back into mysql by
    * converting them to a Alchemy Database table
{{{
CREATE TABLE back_to_sql AS DUMP redis_object
}}}
    * export from Alchemy Database to mysql w/ the DUMP TO MYSQL command (piped into mysql)
{{{
DUMP back_to_sql TO MYSQL
}}}
    createTableFromRedisObject() and dumpToMysql() are demo'ed [http://github.com/JakSprats/predis/blob/master/examples/backup_redis_to_mysql.php here]


=== MYSQL EXAMPLE THREE: Export Table from Mysql To NOSQL and Go Schemaless ===
One of the most mind blowing features of NOSQL is it is SCHEMALESS. This means if you decide to give your users ten new attributes today and 20 new attributes tommorow and next week decide all of those attributes are stupid ... you can add and delete these attributes on-the-fly w/o updating your schema. No "ALTER TABLE ADD/DELETE COLUMN" w/ its unpredicable run-time behaviour. Go schemaless and add "columns" at will, cause they are no longer columns :)<br/>
<br/>
Steps to go from mysql to schemaless nosql
  # Read out a table's contents from mysql and insert them into Alchemy Database<br/>
  A 45 line Ruby example can be found [https://github.com/JakSprats/redis-rb/blob/master/examples/schemaless.rb#L16-61 here]
  # Denormalise the table using the command 
{{{
DENORM table "table:*"
}}}
Thats it, you will now have one hash-table per sql-table-row with names "table:1, table:2, table:3, ....".<br/>
You are schemaless.
<br/>
<br/>
<br/>

== REDIS EXAMPLES ==
=== REDIS EXAMPLE ONE: backup redis data to Mysql for Data Mining or Data Analytics ===
Alchemy Database provides the ability to normalise a redis data structure (list,set,zset & hash) to a SQL table. It is then trivial to dump this table to file and have Mysql read it in and archive it. From there it is simple to do datamining on your redis objects by merging them into aggregate tables and performing relational logic on said tables.<br/>
<br/>
This can be done at command line with the commands: (the output of the 2nd command can be read straight into mysql)
{{{
CREATE TABLE X AS DUMP Redis_Object
DUMP X TO MYSQL
}}}
[https://github.com/JakSprats/redis-rb/blob/master/examples/backup_redis_to_mysql.rb Here] is a 40 line php script that backs up EVERY KEY (that isnt a string or index:) in your redisDB to mysql 


=== REDIS EXAMPLE TWO: create a Mysql Cache for "old" redis data ===
In Memory Databases are fantastic, until they get low on RAM, which is somewhat of an eventuality.<br/>
<br/>
Its a good practice to archive data you probably will not access again on the frontend from your In Memory Database to a disk based Database (e.g. mysql) and then build a thin cache layer that will retrieve archived data from the disk based Database as needed.<br/>
<br/>
Building the thin cache layer is surprisingly easy to program. Here is a PHP script that creates a Mysql Cache for the redis ZSET. The object can be found [http://github.com/JakSprats/predis/blob/master/examples/ZsetCache.php here] _(only 100 lines)_ and an example using tweets can be found [http://github.com/JakSprats/predis/blob/master/examples/tweet/tweet_archiver.php here].<br/>
<br/>
With this ZSetCache class, you need only to define your own achiving criterion and scripts, (specific to your data - some peoples data is old after 30 minutes, some after 30 days)<br/>
<br/>
The approach: cache-old-data-to-disk is a fantastic way to ensure your In Memory Database stays well within its RAM's size and can also be used to avoid spending money on hardware by avoiding the need to scale horizontally.
<br/>
<br/>
== INSWAP EXAMPLE ==
*coming soon*